{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importing Libraries\")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2, os, random, shutil\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "from preprocess import *\n",
    "np.set_printoptions(threshold = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet Loss Function\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometrical Distance between Images\n",
    "def find_distance(image_path, identity, database, model):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Images in a location\n",
    "def create_datadict(database_location, model):\n",
    "    data_dict = {}\n",
    "    for celeb in os.listdir(database_location):\n",
    "        data_dict.update({ celeb : img_to_encoding(database_location + celeb, model) })\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_distances(image_location, database, model):\n",
    "    dist_dict = {}\n",
    "    for id in database.keys():\n",
    "        dist = find_distance(image_location, id, database, model)\n",
    "        dist_dict.update({ id : dist })\n",
    "    return dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_loc, name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (18, 5))\n",
    "    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(cv2.cvtColor(cv2.imread(image_loc[i]), cv2.COLOR_BGR2RGB))\n",
    "        ax.set_xlabel(name[i])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    print(\"Loading Face Recognition Model ....\")\n",
    "    FRmodel = faceRecoModel(input_shape = (3, 96, 96))\n",
    "    print(\"Compiling Face Recognition Model ....\")\n",
    "    FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "    print(\"Loading Weights for Face Recognition Model ....\")\n",
    "    load_weights_from_FaceNet(FRmodel)\n",
    "    preprocess_database(\"./Database/Images/\")\n",
    "    print(\"Generating Database of Available Images\")\n",
    "    database = create_datadict(\"./Database/Images/\", FRmodel)\n",
    "    preprocess_testcases(\"./Testcases/Preprocessed/\")\n",
    "    for file in os.listdir(\"./TestCases/Preprocessed/\"):\n",
    "        dist_dict = find_image_distances(\"./TestCases/Preprocessed/\" + file, database, FRmodel)\n",
    "        celeb_filename = min(dist_dict, key = dist_dict.get)\n",
    "        celeb = celeb_filename.split('.')[0]\n",
    "        display_image(\n",
    "            [\"./TestCases/Actual/\" + file, \"./Database/Celebs/\" + celeb_filename],\n",
    "            [file.split(\".\")[0], celeb]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver Code\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
